# ═══════════════════════════════════════════════════════════
# MASX-GSGI — Production Environment (CPU / 32 GB RAM)
# ═══════════════════════════════════════════════════════════

# ── Database (Supabase via pgBouncer) ────────────────────
DATABASE_URL=postgresql+asyncpg://postgres.uejhhobzicbxysgmlduc:tQ2XuWxSprgfjrIk@aws-0-eu-central-1.pooler.supabase.com:6543/postgres
DATABASE_URL_SYNC=postgresql://postgres.uejhhobzicbxysgmlduc:tQ2XuWxSprgfjrIk@aws-0-eu-central-1.pooler.supabase.com:6543/postgres

# ── LLM Provider (Together AI) ───────────────────────────
LLM_PROVIDER=together
LLM_BASE_URL=https://api.together.xyz/v1
LLM_MODEL=meta-llama/Llama-3.2-3B-Instruct-Turbo
LLM_API_KEY=tgp_v1_KYFhSzNmr09ZA0TT7qyLC2Dv9mCRt5J4IQdo8K5Ifvg
LLM_BATCH_ENABLED=false
LLM_RPM_LIMIT=599

# ── Fallback LLM (Mistral) ──────────────────────────────
LLM_PROVIDER_FALLBACK=mistral
LLM_FALLBACK_BASE_URL=https://api.mistral.ai/v1
LLM_FALLBACK_MODEL=mistral-small-latest
LLM_FALLBACK_API_KEY=fJ5ugSknGg841iG46ZeJGxH1YAEdOLP4

# ── Pipeline ─────────────────────────────────────────────
PIPELINE_TIER=C
PIPELINE_API_KEY=EyJdxuE_ec6Caz_vWOu-A-ZgQaNt4vdu8ZR4swhW-mI

# ── Concurrency (tuned for 32 GB RAM) ────────────────────
MAX_CONCURRENT_FETCHES=50
PER_DOMAIN_CONCURRENCY=3
FETCH_TIMEOUT_SECONDS=30
REQUEST_DELAY_SECONDS=0.25
LLM_SUMMARIZE_BATCH_SIZE=20

# ── Embedding ────────────────────────────────────────────
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# ── Clustering ───────────────────────────────────────────
CLUSTER_KNN_K=10
CLUSTER_COSINE_THRESHOLD=0.65

# ── Local Summarizer (DistilBART — CPU, 8 workers) ──────
LOCAL_SUMMARIZER_MODEL=sshleifer/distilbart-cnn-12-6
LOCAL_SUMMARIZER_ONNX_DIR=models/distilbart-cnn-onnx
LOCAL_SUMMARIZER_WORKERS=8

# ── Extraction ───────────────────────────────────────────
MIN_CONTENT_LENGTH=200
PLAYWRIGHT_ENABLED=false
EXTRACTION_TIMEOUT_SECONDS=20

# ── Dedupe ───────────────────────────────────────────────
MINHASH_NUM_PERM=128
MINHASH_THRESHOLD=0.8

# ── Scoring ──────────────────────────────────────────────
PREMIUM_LLM_TOP_PCT=0.10

# ── ML Models ────────────────────────────────────────────
IPTC_MODEL_DIR=models/iptc-classifier
NER_MODEL=Davlan/distilbert-base-multilingual-cased-ner-hrl
FASTTEXT_MODEL_DIR=models

# ── Logging (structured JSON for production) ─────────────
LOG_LEVEL=INFO
LOG_FORMAT=json

# ── Server ───────────────────────────────────────────────
PORT=8080
